\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{wikipedia-gpu:2015}
\citation{CUDA_toolkit_doc}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Signal Processing with GPUs}{15}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:gpu}{{5}{15}{Signal Processing with GPUs}{chapter.5}{}}
\@writefile{brf}{\backcite{wikipedia-gpu:2015}{{15}{5}{chapter.5}}}
\@writefile{brf}{\backcite{CUDA_toolkit_doc}{{15}{5}{chapter.5}}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Simple GPU code example}{15}{section.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces A block diagram of how a CPU sequentially performs vector addition.}}{16}{figure.5.1}}
\newlabel{fig:CPUaddBlockDiagram}{{5.1}{16}{Simple GPU code example}{figure.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces A block diagram of how a GPU performs vector addition in parallel.}}{16}{figure.5.2}}
\newlabel{fig:GPUaddBlockDiagram}{{5.2}{16}{Simple GPU code example}{figure.5.2}{}}
\newlabel{code:GPUvsCPU}{{5.1}{17}{Comparison of CPU verse GPU code}{lstlisting.5.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.1}Comparison of CPU verse GPU code.}{17}{lstlisting.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}GPU kernel using threads and thread blocks}{18}{section.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Block $0$ $32$ threads launched in $4$ thread blocks with $8$ threads per block.}}{19}{figure.5.3}}
\newlabel{fig:threadsBlocks32}{{5.3}{19}{GPU kernel using threads and thread blocks}{figure.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces $36$ threads launched in $5$ thread blocks with $8$ threads per block with $4$ idle threads.}}{19}{figure.5.4}}
\newlabel{fig:threadsBlocks36}{{5.4}{19}{GPU kernel using threads and thread blocks}{figure.5.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}GPU memory}{19}{section.5.3}}
\newlabel{sec:GPU_memory}{{5.3}{19}{GPU memory}{section.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces A block diagram where local, shared, and global memory is located. Each thread has private local memory. Each thread block has private shared memory. The GPU has global memory that all threads can access.}}{20}{figure.5.5}}
\newlabel{fig:fullGPUmemBlockDiagram}{{5.5}{20}{GPU memory}{figure.5.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces The computational resources available with three NVIDIA GPUs used in this thesis (1x Tesla K40c 2x Tesla K20c).}}{20}{table.5.1}}
\newlabel{tab:gpu-resources_jeffs}{{5.1}{20}{GPU memory}{table.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces NVIDIA Tesla K40c and K20c.}}{21}{figure.5.6}}
\newlabel{fig:GPUpicture}{{5.6}{21}{GPU memory}{figure.5.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Example of an NVIDIA GPU card. The SRAM is shown to be boxed in yellow. The GPU chip is shown to be boxed in red.}}{21}{figure.5.7}}
\newlabel{fig:GPUarch}{{5.7}{21}{GPU memory}{figure.5.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Cuda Libraries}{22}{section.5.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Thread Optimization}{22}{section.5.5}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}CPU GPU Pipelining}{23}{section.5.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces The GPU convolution thread optimization of a $12672$ length signal with a $186$ tap filter using shared memory. $192$ is the optimal number of threads per block executing in $0.1101$ms. Note that at least $186$ threads per block must be launched to compute correct output.}}{24}{figure.5.8}}
\newlabel{fig:ConvGPU_shared_12672_186taps}{{5.8}{24}{Thread Optimization}{figure.5.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces ConvGPU thread optimization 128 threads per block 0.006811.}}{25}{figure.5.9}}
\newlabel{fig:ConvGPU_global_12672_186taps}{{5.9}{25}{Thread Optimization}{figure.5.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces The typical approach of CPU and GPU operations. This block diagram shows a Profile of Listing \ref  {code:noPipe}.}}{25}{figure.5.10}}
\newlabel{fig:concurrentCPU_nonBlocking}{{5.10}{25}{CPU GPU Pipelining}{figure.5.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces GPU and CPU operations can be pipelined. This block diagram shows a Profile of Listing \ref  {code:pipe}.}}{26}{figure.5.11}}
\newlabel{fig:concurrentCPU_blocking}{{5.11}{26}{CPU GPU Pipelining}{figure.5.11}{}}
\newlabel{code:noPipe}{{5.2}{26}{Example code Simple example of the CPU acquiring data from myADC, copying from host to device, processing data on the device then copying from device to host. No processing occurs on device while CPU is acquiring data}{lstlisting.5.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.2}Example code Simple example of the CPU acquiring data from myADC, copying from host to device, processing data on the device then copying from device to host. No processing occurs on device while CPU is acquiring data.}{26}{lstlisting.5.2}}
\newlabel{code:pipe}{{5.3}{26}{Example code Simple of the CPU acquiring data from myADC, copying from host to device, processing data on the device then copying from device to host. No processing occurs on device while CPU is acquiring data}{lstlisting.5.3}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.3}Example code Simple of the CPU acquiring data from myADC, copying from host to device, processing data on the device then copying from device to host. No processing occurs on device while CPU is acquiring data.}{26}{lstlisting.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces A block diagram of pipelining a CPU with three GPUs.}}{27}{figure.5.12}}
\newlabel{fig:concurrentCPU_nonBlocking_multiGPU}{{5.12}{27}{CPU GPU Pipelining}{figure.5.12}{}}
\@setckpt{gpu_intro}{
\setcounter{page}{28}
\setcounter{equation}{1}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{6}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{12}
\setcounter{table}{1}
\setcounter{parentequation}{0}
\setcounter{r@tfl@t}{0}
\setcounter{cp@cnt}{0}
\setcounter{cp@tempcnt}{0}
\setcounter{lstnumber}{31}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{22}
\setcounter{lstlisting}{3}
\setcounter{section@level}{1}
}
