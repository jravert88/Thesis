%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%% systemOverview
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% \cleardoublepage
\chapter{System Overview}
\label{sec:systemOverview}




The PAQ system is suited very well for batched processing.
Each $1.907$ second set has $3104$ packets or batches of data as shown in Figure \ref{fig:packet_batch_set}.
If an operation is done on each packet, available CUDA batched libraries should always be used.
For simplicity, every block diagram shown in this chapter only applies to a single batch.
Every block diagram is batched and applied to $3104$ iNET packets.
\begin{figure}
	\caption{Diagram showing the relationships between $z(n)$, $\rho(n)$ and $b(n)$.}
	\centering\includegraphics[width=5.94in/100*55]{figures/eq_GPUimplementation/packet_batch_set.pdf}
	\label{fig:packet_batch_set}
\end{figure}


\section{Batched Convolution}
Chapter \ref{chap:gpu} delved into comparing a single convolution in CPUs and GPUs in the time domain or frequency domain.
As talked about in Chapter blah, system overview, We dont only have a packet or batch, we have $3104$ packets or batches.
When we perform convolution we convolve $3104$ signals with $3104$ filters.
So...
How does the problem change?
Obviously doing batched convolution in a CPU will not be feasible and wont be considered.

Lets stay in GPU land.
Should we do convolution in the time domain or the frequency domain?
Are there draw backs to staying in the time domain? 
If we do convolution in the time domain, should we use shared memory?
Are there draw backs for going to the frequency domain? 

Get timing of convolution in the time domain global, time domain shared, time domain frequency.

There is one very important thing we have over looked...
We are doing just one convolution...we are doing two.
We have to convolve with the equalizer AND the numerically optimized detection filter $\mathbf{h}_{NO}$.
If we stay in the time domain, we have to do two cascaded convolutions.
Two convolutions takes...twice the time....
If we go to the frequency domain, the point to point or hadamard product is done with 3 inputs rather than 2.
Convolving with 2 inputs vs even 10 inputs is about the same.
The only required part is performing the FFT on the inputs and performing the $N$ way multiply...

Well, $\mathbf{h}_{NO}$ doesn't change, so we compute the FFT of the detection filter $\mathbf{H}_{NO}$ and store it.
So doing the convolution requires taking the FFT of 2 vectors $\mathbf{c}$ and $\mathbf{r}$.
After the hadamard product, the functions independent of how many filters we are convolving with accept for we may have to trip off different parts depending on what we are convolving with.

Optimizing convolution speeds up every equalizer because every equalizer uses convolution...CMA uses convolution twice per iteration. 

Chapter \ref{chap:eq_eq} the equalizer equations were conditioned for GPU implementation.
This Chapter explains how the equalizers were implemented into GPUs.
Block diagrams will be a very helpful tool to display how the GPU kernels flow.

CUDA has many functions that are ``batched,'' meaning the GPU can apply the same function to each packet.
Don't be confused with the term batch. 
In the PAQ system, a ``batch'' is 1.907 seconds of data or $3103$ or $3104$ packets.
In CUDA, ``batched'' kernels are GPU kernels that are called $3103$ or $3104$ times to run on each iNET packet.
One could say ``The batched kernel runs on a batch of data by processing $3103$ or $3104$ packets.'' 
The CUDA number of batches is how many iNET packets are being processed.

This sections explains how each equalizer is computed and how the ``numerically optimized'' $H_\text{NO}$ detection filter is applied in each case \cite[Fig. 3]{perrins:2013}.





\section{Overview}
This chapter gives a high lever overview of the algorithms required to implement equalizers in GPUs. 
As shown in chapter blah, an equalizer uses the channel estimate and the noise varinace to be calculated.
The channel estimate is found by estimating the channel based on the preamble.
The noise estimate is found by estimating the noise varinace from the preamble after the channel has been estimated.
The frequency offset also needs to be removed before estimating the channel and noise.
All estimators are data aided. The preamble has to be found before any estimators can be ran.


A block diagram of the estimators is shown in Figure \ref{fig:estimatorBlock}.
A block diagram of the equalization and symbol detector is shown in Figure \ref{fig:estimatorBlock}.
The estimators and symbol detector will be explained briefly in this chapter.
The equalizer computation and detection filter process in the dashed box will be explained in chapter \ref{chap:eq_eq}.
\begin{figure}
	\caption{A block diagram of the estimation process.}
	\centering\includegraphics[width=10.33in/100*55]{figures/systemOverview/estimatorBlock.pdf}
	\label{fig:estimatorBlock}
\end{figure}
\begin{figure}
	\caption{A block diagram of the equalization and symbol detector process.}
	\centering\includegraphics[width=9.35in/100*55]{figures/systemOverview/ProcessingBlock.pdf}
	\label{fig:ProcessingBlock}
\end{figure}

\section{Preamble Detection}
The received samples in this thesis has the iNET packet structure shown in Figure \ref{fig:packet}.
The iNET packet consists of a preamble and ASM periodically inserted into the data stream.
The iNET preamble and ASM bits are inserted every 6144 data bits.
The received signal is sampled at 2 samples/bit, making an $\Lpkt=12672$ sample iNET packet.
The iNET preamble comprises eight repetitions of the 16-bit sequence $\text{CD98}_\text{hex}$ and the ASM field
\begin{equation}
034776C72728950B0_\text{hex}
\end{equation}
Each 16-bit sequence $\text{CD98}_\text{hex}$ sampled at two samples/bit are $L_q=32$ samples long.
\begin{figure}
	\caption{The iNET packet structure.}
	\centering\includegraphics[width=9.47in/100*55]{figures/systemOverview/packetStructure.pdf}
	\label{fig:packet}
\end{figure}

To compute data-aided preamble assisted equalizers, preambles in the received signal are found then used to estimate various parameters.
The goal of the preamble detection step is to structure the received samples into length $\Lpkt$ vectors with the structure shown in Figure \ref{fig:packet}.
Each vector contains $\Lp = 256$ preamble samples, $\Lasm = 136$ ASM samples and $\Ldata = 12288$ data samples.
The full length of a vector is $\Lp + \Lasm + \Ldata = 12672$.

Before the structureing the received samples into packets, the preambles are found using a preamble detector explained in \cite{preamble_detector}.
Equations \eqref{eq:gpu-L-4} through \eqref{eq:gpu-L-pedone-geoghegan-4} have been optimized for GPUs and are implemented directly.
\begin{equation}
	L(u) = \sum_{m=0}^{7}
		\left[ I^2(n,m) + Q^2(n,m) \right]
	\label{eq:gpu-L-4}
\end{equation}
where the inner summations are
\begin{multline}
	I(n,m) \approx \sum_{\ell\in\mathcal{L}_1}r_R(\ell+32m+n)
			- \sum_{\ell\in\mathcal{L}_2}r_R(\ell+32m+n)
			+ \sum_{\ell\in\mathcal{L}_3}r_I(\ell+32m+n)
			- \sum_{\ell\in\mathcal{L}_4}r_I(\ell+32m+n)
			\\
			+ 0.7071 \left[
				\sum_{\ell\in\mathcal{L}_5}r_R(\ell+32m+n)
				- \sum_{\ell\in\mathcal{L}_6}r_R(\ell+32m+n)
			\right. \\
			\left.
				+ \sum_{\ell\in\mathcal{L}_7}r_I(\ell+32m+n)
				- \sum_{\ell\in\mathcal{L}_8}r_I(\ell+32m+n)
			\right],
	\label{eq:gpu-L-pedone-geoghegan-2}
\end{multline}
and
\begin{multline}
	Q(n,m) \approx \sum_{\ell\in\mathcal{L}_1}r_I(\ell+32m+n)
			- \sum_{\ell\in\mathcal{L}_2}r_I(\ell+32m+n)
			\\
			- \sum_{\ell\in\mathcal{L}_3}r_R(\ell+32m+n)
			+ \sum_{\ell\in\mathcal{L}_4}r_R(\ell+32m+n)
			\\
			+ 0.7071 \left[
				\sum_{\ell\in\mathcal{L}_5}r_I(\ell+32m+n)
				- \sum_{\ell\in\mathcal{L}_6}r_I(\ell+32m+n)
			\right. \\
			\left.
				- \sum_{\ell\in\mathcal{L}_7}r_R(\ell+32m+n)
				+ \sum_{\ell\in\mathcal{L}_8}r_R(\ell+32m+n)
			\right]
		\label{eq:gpu-L-pedone-geoghegan-3}
\end{multline}
with
\begin{equation}
	\begin{split}
	\mathcal{L}_1 &= \{ 0, 8, 16, 24 \}\\
	\mathcal{L}_2 &= \{ 4, 20 \}\\
	\mathcal{L}_3 &= \{ 2, 10, 14, 22 \}\\
	\mathcal{L}_4 &= \{ 6, 18, 26, 30 \}\\
	\mathcal{L}_5 &= \{ 1, 7,  9, 15, 17, 23, 25, 31 \}\\
	\mathcal{L}_6 &= \{ 3, 5, 11, 12, 13, 19, 21, 27, 28, 29 \}\\
	\mathcal{L}_7 &= \{ 1, 3,  9, 11, 12, 13, 15, 21, 23 \}\\
	\mathcal{L}_8 &= \{ 5, 7, 17, 19, 25, 27, 28, 29, 31 \}.
\end{split}
\label{eq:gpu-L-pedone-geoghegan-4}
\end{equation}

A correlation peak in $L(u)$ indicate the starting index $k$ of a preamble.
The vector $\mathbf{r}_\text{p}$ in Figure \ref{fig:estimatorBlock} is defined by
\begin{equation}
\mathbf{r}_\text{p} = 
\begin{bmatrix}
r(k) \\ 
\vdots \\ 
r(k+\Lpkt-1)
\end{bmatrix}
=
\begin{bmatrix}
r_\text{p}(0) \\ 
\vdots \\ 
r_\text{p}(\Lpkt-1)
\end{bmatrix}
\end{equation}

\section{Frequency Offset Compensation}
The frequency offset estimator shown in Figure \ref{fig:estimatorBlock} is the estimator taken from \cite[eq. (24)]{rice2014frequency}.
With the notation adjusted slightly, the frequency offset estimate is
\begin{equation}
	\hat{\omega}_0 = \frac{1}{L_q} \arg\left\{ \sum_{n=i+2L_q}^{i+7L_q-1} r_\text{p}(n)r_\text{p}^\ast(n-L_q)\right\}
	\quad
\text{for} \;
i=1,2,3,4,5.
	\label{eq:jeff-ML-w-final3}
\end{equation}
The frequency offset is estimated for every packet or each vector $\mathbf{r}_\text{p}$.

The frequency offset is compensated for by derotating the packet structured samples by the estimated offset
\begin{equation}
	r(n) = r_\text{p}(n) e^{-j\hat{\omega}_0}.
	\label{eq:frequency_compensation}
\end{equation}
Equations \eqref{eq:jeff-ML-w-final3} and \eqref{eq:frequency_compensation} are easily implemented into GPUs. 

\section{Channel Estimation}
\label{sec:channel_estimation}
The channel estimator is the ML estimator taken from \cite[eq. 8]{rice-afran-saquib-cole-rhodes-moazzami:2014}.
\begin{equation}
\hat{\mathbf{h}} = \underbrace{ \left( \mathbf{X}^\dag\mathbf{X} \right)^{-1} \mathbf{X}^\dag}_{\mathbf{X}_\text{lpi}}\mathbf{r}
\end{equation}
where $\mathbf{X}$ is a convolution matrix formed from the ideal preamble and ASM samples
and $\mathbf{X}_\text{lpi}$ is the left psudo-inverse of $\mathbf{X}$.
The ML channel estimator is the matrix operation
\begin{equation}
\hat{\mathbf{h}} = \mathbf{X}_\text{lpi} \mathbf{r}.
\end{equation}
The matrix operation $\mathbf{X}_\text{lpi} \mathbf{r}$ maps simply and efficiently in GPUs using cuBLAS.


\section{Noise Variance Estimation}
\label{sec:noise_variance_estimation}
The noise variance estimator is also taken from \cite[eq. 9]{rice-afran-saquib-cole-rhodes-moazzami:2014}
\begin{equation}
	\hat{\sigma}_w^2 = \frac{1}{2\rho} \left| \mathbf{r}-\mathbf{X}\hat{\mathbf{h}}\right|^2
	\label{eq:ML-s2-final3}
\end{equation}
where
\begin{equation}
	\rho = {\rm Trace} \left\{ \mathbf{I} -  \mathbf{X}\left(\mathbf{X}^\dag\mathbf{X}\right)^{-1}\mathbf{X}^\dag \right\}.
\end{equation}
Equation \eqref{eq:ML-s2-final3} is easily implemented into GPUs.
	

\section{Symbol-by-Symbol Detector}
\label{sec:oqpsk_detector}
The symbol by symbol detector block in Figure \ref{fig:ProcessingBlock} is a Offset Quadrature Phase Shift Keying (OQPSK) detector.
Using the simple OQPSK detector in place of the complex MLSE SOQPSK-TG detector leads to less than $1$dB in bit error rate \cite{perrins:2013}.
\begin{figure}
	\caption{Offset Quadriture Phase Shift Keying symbol by symbol detector.}
	\centering\includegraphics[width=6in]{figures/systemOverview/OQPSK.pdf}
	\label{fig:OQPSK}
\end{figure}

A Phase Lock Loop (PLL) is needed in the SxS OQPSK detector to track out residual frequency offset.
The residual frequency offset results from the frequency offset estimation error.
While phase offset, timing offset and multipath are combated with equalizers, a PLL is required to eliminate residual frequency offset.
The PLL tracks out the residual frequency offset using a feedback control loop.

Implementing the PLL with a feedback loop seems like it may be challenging in GPUs because it cannot be parallelized.
While the PLL cannot be parallelized on a sample by sample basis, it can be parallelized on a packet by packet basis.
Running the PLL and detector serially through a full packet of data is still relatively fast because each iteration of the PLL and detector is computationally light.